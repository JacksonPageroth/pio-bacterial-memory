{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl \n",
    "import polars_ols as pls\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "def unzip_and_get_csv_path(zip_file_path, extract_to_folder=None):\n",
    "    \"\"\"\n",
    "    Unzips a file and retrieves the path(s) of any resulting CSV files.\n",
    "\n",
    "    Args:\n",
    "        zip_file_path (str): Path to the zip file.\n",
    "        extract_to_folder (str): Folder where files should be extracted. \n",
    "                                 Defaults to the same directory as the zip file.\n",
    "\n",
    "    Returns:\n",
    "        list: List of paths to the extracted CSV files.\n",
    "    \"\"\"\n",
    "    if extract_to_folder is None:\n",
    "        extract_to_folder = os.path.dirname(zip_file_path)\n",
    "    \n",
    "    csv_paths = []\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        # Extract all files\n",
    "        zip_ref.extractall(extract_to_folder)\n",
    "        \n",
    "        # List extracted files and filter for CSVs\n",
    "        for file_name in zip_ref.namelist():\n",
    "            extracted_file_path = os.path.join(extract_to_folder, file_name)\n",
    "            if file_name.lower().endswith('.csv'):\n",
    "                csv_paths.append(extracted_file_path)\n",
    "    \n",
    "    return csv_paths[0]\n",
    "\n",
    "# Get the list of CSV files in the Downloads folder\n",
    "csv_files = glob.glob(os.path.expanduser('~/Downloads/*.csv'))\n",
    "\n",
    "if len(csv_files) == 0:\n",
    "    latest_csv = unzip_and_get_csv_path('./od_logs/latest_od_data.zip')\n",
    "else:\n",
    "    # Find the most recent file based on modification time\n",
    "    latest_csv = max(csv_files, key=os.path.getmtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the latest CSV file\n",
    "df = pl.read_csv(latest_csv).select(\"od_reading\", \"timestamp_localtime\", \"pioreactor_unit\").rename({\"od_reading\": \"OD600\", \"timestamp_localtime\": \"Time\", \"pioreactor_unit\": \"Unit\"})\n",
    "\n",
    "# If you want to load a specific CSV file, you can use the following line:\n",
    "# df = pl.scan_csv(insert csv here).select(\"OD600\", \"Time\", \"Unit\")\n",
    "\n",
    "# Dictionary to map 'Pioreactor name' to new values\n",
    "name_dict = {\n",
    "    'worker2': 'W2 - 35 Control',\n",
    "    'worker3': 'W3 - Replicate 1',\n",
    "    'worker4': 'W4 - Replicate 2',\n",
    "    'worker5': 'W5 - 55 Control'\n",
    "}\n",
    "\n",
    "optimal_controls = [\"W2 - 35 Control\"]\n",
    "stressed_controls = [\"W5 - 55 Control\"]\n",
    "controls = [\"W5 - 55 Control\", \"W2 - 35 Control\"]\n",
    "replicates = [\"W3 - Replicate 1\", \"W4 - Replicate 2\"]\n",
    "\n",
    "# Define the corresponding transformations for each condition\n",
    "equations = {\n",
    "    \"W2 - 35 Control\": (1.348628103, 0.077), \n",
    "    \"W3 - Replicate 1\": (2.073660771, .077), \n",
    "    \"W4 - Replicate 2\": (2.204291876, .077), \n",
    "    \"W5 - 55 Control\": (1.169484467, .077), \n",
    "}\n",
    "\n",
    "threshold_od = 0.24  # Point after which we subculture\n",
    "\n",
    "# Replace values in 'Pioreactor name' column using the dictionary\n",
    "df = df.with_columns(pl.col(\"Unit\").replace_strict(name_dict))\n",
    "\n",
    "# Apply the equation\n",
    "a = pl.col(\"Unit\").replace_strict(equations).list.first()\n",
    "b = pl.col(\"Unit\").replace_strict(equations).list.last()\n",
    "df = df.with_columns((pl.col(\"OD600\") * a + b))\n",
    "\n",
    "# Convert 'timestamp_localtime' to datetime format\n",
    "df = df.with_columns(pl.col(\"Time\").str.strptime(pl.Datetime, \"%Y-%m-%d %H:%M:%S\"))\n",
    "\n",
    "# Filter out artifacts\n",
    "df = df.filter(pl.col(\"Time\") >= pl.col(\"Time\").min().dt.offset_by(\"5m\"))\n",
    "df= df.with_columns((pl.col(\"Time\").sub(pl.col(\"Time\").first()).dt.total_seconds()/3600).alias(\"Hours\"))\n",
    "df = df.filter((pl.col(\"Unit\").eq(\"W5 - 55 Control\") & pl.col(\"Hours\").ge(104.2) &  pl.col(\"Hours\").le(104.4)).not_())\n",
    "\n",
    "df = df.sort(\"Unit\", \"Hours\")\n",
    "\n",
    "# Plotting the growth curves using the new 'Transformed OD' column\n",
    "hue_order = [\"W2 - 35 Control\", \"W5 - 55 Control\", \"W3 - Replicate 1\", \"W4 - Replicate 2\"]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 6.5))\n",
    "sns.lineplot(x=\"Time\", y=\"OD600\", hue=\"Unit\", hue_order=hue_order,\n",
    "             markersize=8, sizes=(1, 8), data=df.to_pandas(), ax=ax, palette=[\"blue\", \"red\", \"green\", \"mediumseagreen\"])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%m/%d %H:%M\"))\n",
    "plt.axhline(y=threshold_od, color='r', linestyle='--')\n",
    "# Set major ticks to every 6 hours\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=6))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%H\"))\n",
    "ax.set_xlabel(\"Time\")\n",
    "\n",
    "# Create a secondary x-axis for date display\n",
    "secax = ax.secondary_xaxis(-0.1)\n",
    "secax.xaxis.set_major_locator(mdates.DayLocator())\n",
    "secax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y-%m-%d\"))\n",
    "secax.set_xlabel(\"Date\")\n",
    "ax.set_title('Pioreactor Transformed OD Curves')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condition for incrementing 'step'\n",
    "step_cond = (pl.col(\"OD600\").shift(1) - pl.col(\"OD600\") > 0.03)\n",
    "\n",
    "# Use cumulative sum over the 'step_condition' to increment each time it's True\n",
    "df = df.with_columns(pl.when(step_cond).then(1).otherwise(0).cum_sum().add(1).over(pl.col(\"Unit\")).alias(\"Step\"))\n",
    "\n",
    "# Add condition to the df\n",
    "df = df.with_columns(pl.when((pl.col(\"Step\") % 2 == 1) & (pl.col(\"Unit\").is_in(replicates)))\n",
    "                     .then(pl.lit(\"Optimal\"))\n",
    "                     .otherwise(pl.when((pl.col(\"Step\") % 2 == 0) & (pl.col(\"Unit\").is_in(replicates)))\n",
    "                                .then(pl.lit(\"Stressed\"))\n",
    "                                .otherwise(pl.when(pl.col(\"Unit\").is_in(stressed_controls))\n",
    "                                           .then(pl.lit(\"Stressed\"))\n",
    "                                           .otherwise(pl.when(pl.col(\"Unit\").is_in(optimal_controls))\n",
    "                                                      .then(pl.lit(\"Optimal\")))))\n",
    "                     .alias(\"Condition\"))\n",
    "\n",
    "# Discard the first 10 points in every step (because of subculture spike)\n",
    "df = df.with_columns(pl.cum_count(\"OD600\").over(\"Unit\", \"Step\").alias(\"index\")).filter(pl.col(\"index\") > 5).drop(\"index\")\n",
    "\n",
    "# Plotting the growth curves using the new 'Transformed OD' column\n",
    "col_order = [\"W3 - Replicate 1\", \"W4 - Replicate 2\", \"W2 - 35 Control\", \"W5 - 55 Control\"]\n",
    "g = sns.relplot(x=\"Hours\", y=\"OD600\", hue=\"Condition\", style=\"Step\", col=\"Unit\", col_wrap=2, col_order=col_order,\n",
    "             markersize=8, sizes=(1, 8), data=df.to_pandas(), kind=\"line\", hue_order=[\"Optimal\", \"Stressed\"], palette=[\"blue\", \"red\"])\n",
    "\n",
    "for ax in g.axes.flatten():\n",
    "    ax.axhline(y=threshold_od, color='r', linestyle='--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blank = 0.077\n",
    "\n",
    "pioreactors = df.get_column(\"Unit\").unique()\n",
    "\n",
    "# Process data for each pioreactor\n",
    "results = []\n",
    "for pioreactor in pioreactors:\n",
    "    pio_df = df.filter(pl.col(\"Unit\") == pioreactor)\n",
    "    pio_df = pio_df.with_columns(((pl.col(\"OD600\") - blank)/(pl.col(\"OD600\").min() - blank)).over(\"Step\").alias(\"Normalized OD\"))\n",
    "    results.append(pio_df)\n",
    "\n",
    "df = pl.concat(results)\n",
    "\n",
    "# Plotting the growth curves using the new 'Transformed OD' column\n",
    "col_order = [\"W3 - Replicate 1\", \"W4 - Replicate 2\", \"W2 - 35 Control\", \"W5 - 55 Control\"]\n",
    "g = sns.relplot(x=\"Hours\", y=\"Normalized OD\", hue=\"Condition\", style=\"Step\", col=\"Unit\", col_wrap=2, col_order=col_order,\n",
    "             markersize=8, sizes=(1, 8), data=df.to_pandas(), kind=\"line\", hue_order=[\"Optimal\", \"Stressed\"], palette=[\"blue\", \"red\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy \n",
    "\n",
    "# Initialize storage for plot data\n",
    "plot_data = {\"Type\": [], \"Slope\": [], \"Condition\": [], \"Step\": [], \"Intercept\": [], \"Unit\": []}\n",
    "pioreactors = df.get_column(\"Unit\").unique()\n",
    "\n",
    "# Process data for each pioreactor\n",
    "for pioreactor in pioreactors:\n",
    "    pio_df = df.filter(pl.col(\"Unit\") == pioreactor)\n",
    "\n",
    "    # For each step except the one underway\n",
    "    for step in pio_df.get_column(\"Step\").unique()[:-1]:\n",
    "        # Get the step data\n",
    "        step_df = pio_df.filter(pl.col(\"Step\") == step).sort(\"Hours\").gather_every(200)\n",
    "\n",
    "        # Fit a curve throguh it \n",
    "        \n",
    "        import polars as pl\n",
    "        import numpy as np\n",
    "        from scipy.optimize import curve_fit\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        # Extract columns into numpy arrays\n",
    "        x = step_df[\"Hours\"].to_numpy()\n",
    "        y = step_df[\"OD600\"].to_numpy()\n",
    "        \n",
    "        # calculate polynomial\n",
    "        def exp(t, a, b):\n",
    "            return a*np.exp(b*t)\n",
    "            \n",
    "        popt, pcov = scipy.optimize.curve_fit(exp,  x,  y, p0=(0.04, 0.06))\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.plot(x, y, 'ko', label=\"Original Noised Data\")\n",
    "        plt.plot(x, exp(x, *popt), 'r-', label=\"Fitted Curve\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print(popt)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = {\"Type\": [], \"Time (h)\": [], \"Condition\": [], \"Step\":[]}\n",
    "for pioreactor in pioreactors:\n",
    "    pio_df = df.filter(pl.col(\"Unit\").eq(pioreactor))\n",
    "    \n",
    "    for step in pio_df.get_column(\"Step\").unique()[:-1]:\n",
    "        step_df = pio_df.filter(pl.col(\"Step\").eq(step)).sort(\"Time\", descending=False)\n",
    "\n",
    "        try:\n",
    "            thresh_time = (step_df.with_columns((pl.col(\"OD600\") - threshold_od).abs().alias(\"distance\"))\n",
    "                            .filter(pl.col(\"distance\") == pl.col(\"distance\").min())\n",
    "                            .get_column(\"Time\")[0])\n",
    "            start_time = step_df.get_column(\"Time\")[0]\n",
    "            time_to_threshold = (thresh_time - start_time).total_seconds() / 3600\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        plot_df[\"Time (h)\"].append(time_to_threshold)\n",
    "        plot_df[\"Step\"].append(step)\n",
    "\n",
    "        if \"35\" in pioreactor:\n",
    "            plot_df[\"Type\"].append(\"Control\")\n",
    "            plot_df[\"Condition\"].append(\"Optimal\")\n",
    "        elif \"55\" in pioreactor:\n",
    "            plot_df[\"Type\"].append(\"Control\")\n",
    "            plot_df[\"Condition\"].append(\"Stressed\")\n",
    "        elif \"Replicate\" in pioreactor:\n",
    "            plot_df[\"Type\"].append(\"Replicate\")\n",
    "            plot_df[\"Condition\"].append(\"Optimal\" if step % 2 == 1 else \"Stressed\")\n",
    "\n",
    "# Plotting each pioreactor in a separate subplot\n",
    "num_pioreactors = len(pioreactors)\n",
    "plot_df = pl.from_dict(plot_df).to_pandas()\n",
    "sns.scatterplot(plot_df, style=\"Type\", x=\"Step\", y=\"Time (h)\", hue=\"Condition\", hue_order=[\"Optimal\", \"Stressed\"], palette=[\"blue\", \"red\"], markers={\"Replicate\": \"^\", \"Control\": \"X\"})\n",
    "plt.xticks(ticks=range(int(plot_df[\"Step\"].min()), int(plot_df[\"Step\"].max()) + 1))\n",
    "plt.title(\"Time from start of step to subculture threshold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_od = 0.24\n",
    "plot_df = {\"Pioreactor\": [], \"Time (h)\": []}\n",
    "for pioreactor in pioreactors:\n",
    "    pio_df = df.filter(pl.col(\"Unit\").eq(pioreactor)).sort(\"Time\", descending=False)\n",
    "\n",
    "    steps = pio_df.get_column(\"Step\").sort().unique().to_list()\n",
    "    current_od = pio_df.filter(pl.col(\"Step\").eq(steps[-1])).get_column(\"OD600\")[-1]\n",
    "    \n",
    "    last_step = pio_df.filter(pl.col(\"Step\").eq(steps[-3]))\n",
    "    thresh_time = (last_step.with_columns((pl.col(\"OD600\") - predict_od).abs().alias(\"distance\"))\n",
    "                        .filter(pl.col(\"distance\") == pl.col(\"distance\").min())\n",
    "                        .get_column(\"Time\")[0])\n",
    "    \n",
    "    time_in_last_step = (last_step.with_columns((pl.col(\"OD600\") - current_od).abs().alias(\"distance\"))\n",
    "                        .filter(pl.col(\"distance\") == pl.col(\"distance\").min())\n",
    "                        .get_column(\"Time\")[0])\n",
    "    \n",
    "    time_to_threshold = (thresh_time - time_in_last_step).total_seconds() / 3600\n",
    "    \n",
    "    plot_df[\"Time (h)\"].append(time_to_threshold)\n",
    "    plot_df[\"Pioreactor\"].append(pioreactor)\n",
    "\n",
    "\n",
    "# Plotting each pioreactor in a separate subplot\n",
    "num_pioreactors = len(pioreactors)\n",
    "plot_df = pl.from_dict(plot_df).to_pandas()\n",
    "ax = sns.barplot(plot_df, x=\"Pioreactor\", y=\"Time (h)\")\n",
    "ax.bar_label(ax.containers[0], fontsize=10);\n",
    "plt.title(f\"Time in last step of same condition from current OD to {predict_od:.2f}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_od = 0.45\n",
    "plot_df = {\"Pioreactor\": [], \"Time (h)\": []}\n",
    "for pioreactor in pioreactors:\n",
    "    pio_df = df.filter(pl.col(\"Unit\").eq(pioreactor)).sort(\"Time\", descending=False)\n",
    "\n",
    "    steps = pio_df.get_column(\"Step\").sort().unique().to_list()\n",
    "    current_od = pio_df.filter(pl.col(\"Step\").eq(steps[-1])).get_column(\"OD600\")[-1]\n",
    "    \n",
    "    last_step = pio_df.filter(pl.col(\"Step\").eq(steps[-3]))\n",
    "    thresh_time = (last_step.with_columns((pl.col(\"OD600\") - predict_od).abs().alias(\"distance\"))\n",
    "                        .filter(pl.col(\"distance\") == pl.col(\"distance\").min())\n",
    "                        .get_column(\"Time\")[0])\n",
    "    \n",
    "    time_in_last_step = (last_step.with_columns((pl.col(\"OD600\") - current_od).abs().alias(\"distance\"))\n",
    "                        .filter(pl.col(\"distance\") == pl.col(\"distance\").min())\n",
    "                        .get_column(\"Time\")[0])\n",
    "    \n",
    "    time_to_threshold = (thresh_time - time_in_last_step).total_seconds() / 3600\n",
    "\n",
    "    #Add time to threshold to latest timestamp of current step\n",
    "    predicted_time_at_threshold = pio_df.filter(pl.col(\"Step\").eq(steps[-1])).get_column(\"Time\")[-1] + (thresh_time - time_in_last_step)\n",
    "    \n",
    "    print(f\"Predicted time to {predict_od:.2f} for {pioreactor}: {predicted_time_at_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
